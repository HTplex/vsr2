{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a931a00-90c6-4311-92ab-6b3b0350242d",
   "metadata": {},
   "source": [
    "# training t5 for chinese news summery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b527a7c9-c579-42f0-95d5-1d0fba643f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76797\n"
     ]
    }
   ],
   "source": [
    "# data load\n",
    "import pandas as pd    \n",
    "data_sample_path = \"/data/agent_h/news2016zh/news2016zh_valid.json\"\n",
    "data = pd.read_json(path_or_buf=data_sample_path, lines=True)\n",
    "data = data.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "447dffac-86d4-4eb0-ad7f-023dfdc1c98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76797\n",
      "id:  14784\n",
      "{'content': '近日，世界贸易组织(WTO)对中国第六次贸易政策审议在日内瓦顺利结束。此次审议过程中，中国经贸体制、贸易投资领域取得的新进展等多方面得到积极评价，各成员对中国成为其重要经贸合作伙伴十分重视。对此，专家指出，虽然上半年中国进出口双下降，但中国在全球贸易经济中的地位仍不断上升，尤其是中国外贸新旧动能转换释放出的强劲动力，将推动对外贸易继续回稳、向好，也将为全球贸易增长作出重要贡献。新动能持续积累优势上半年，我国进出口同比下降3.3%，进口、出口分别下降4.7%和2.1%。虽然进出口双下降，但我国外贸新旧动能转换正加快进程，贸易结构不断优化。海关总署数据显示，1-6月，我国一般贸易进出口占进出口总值的56.4%，比去年同期提升1.2个百分点;民企出口增长3.6%，占出口总值的46.6%，占比继续保持首位。“一般贸易占比的持续上升体现出中国自主产品的比重在上升、自主创新能力在增强，我国对外贸易正向高附加值端发展，如高新技术产业等新业态在我国外贸发展中的势头已越来越强劲。而民企出口的快速发展带来了更多活力，外贸中的国内资本和投入品的增加，为我国外贸健康发展及结构优化提供了新动能。”国家发改委对外经济研究所国际合作室主任张建平在接受本报记者采访时说。多边、双边经贸合作不断拓展则为我国外贸提供了更大发展空间。海关总署新闻发言人黄颂平指出，上半年，我国对部分“一带一路”沿线国家出口增长。另外，已有22个国家或地区与我国签署并实施自贸协定，上半年，与上述国家或地区的进出口表现好于同期我国进出口总体降幅。商务部研究院国际市场研究部副主任白明表示，上半年，大型成套产品出口保持正增长，这个领域的商品技术含量高，附加值也比较高，跟一般的传统商品相比，它更是我们发展的一个方向。跨境电商贸易、市场采购贸易等新型外贸商业模式正成为新的外贸增长点。中国贸促会副会长尹宗华指出，去年我国的跨境电子商务规模为5.4万亿元人民币，预计今年可能会达到6.5万亿元人民币，对于促进外贸稳增长、调结构发挥了重要作用。“机器换人”降低成本随着新旧动能转换的持续推进，传统动能这一曾经的外贸主要贡献者正面临困境。海关总署数据显示，截至今年6月份，我国的加工贸易进口、出口已经分别连续18个月和16个月下降。今年上半年，加工贸易进出口下降9.8%，拖累我国外贸进出口整体下降约3个百分点。“加工贸易等传统动能对于当前的中国外贸而言仍很重要，它既可以推动贸易均衡发展，也能够为就业提供保障。对于加工贸易的下降，我们在顺应市场规律的前提下，还要充分发掘其潜力，这包括了结构的改善与量的增长。”张建平说，而要充分发掘这一潜力，则要在保留优势的基础上提高其在价值链中的地位，并不断提高贸易便利化水平。 '\n",
      "            '内陆城市承接产业转移的充足后劲也为传统动能再发展提供了条件。根据日前发布的《2015年中国城市外贸竞争力报告》，中西部承接东南沿海产业转移已有起色，一般贸易出口产品高度化与加工贸易增值率两项指标均表现突出，前20强城市中也出现了郑州、西安等中西部城市的身影。“还有一个比较引人注目的就是劳动密集型产品正逐渐找回‘失地’，上半年，其出口出现了正增长，而随着规模的扩大，机器换人的趋势正使得劳动密集型产业的综合成本在下降，这有助于其重新找回国际竞争力。” '\n",
      "            '国家统计局中国经济景气监测中心副主任潘建成说。下半年继续回稳向好新旧动能加速转换的同时，我国外贸面临的国内外压力仍不容忽视。日前WTO发布的全球贸易景气指数为99，低于荣枯线1个百分点，预示三季度世界贸易增长仍将持续低迷。而6月我国外贸出口先导指数为32.7，较上月回落0.4，表明三季度出口再度面临较大下行压力。而根据海关总署调查显示，有61%的企业认为，劳动力、土地等要素成本上升，对企业外贸发展造成很大的压力。此外，我国出口受发展中国家和发达国家的双重挤压，部分产业和订单向外转移。国家发改委学术委员会秘书长张燕生指出，当前，我国对外贸易正告别过去30多年的旧模式，转向新模式，在这一转型过程中，外贸企业面临巨大的压力，光靠企业自身难以实现转型，需要政府和市场的作用。“为了充分应对当前的内外压力，仍需坚持市场主导，政府则要继续推动简政放权，推动贸易便利化发展。各地要落实已经提出来的促进贸易发展措施，并提供更符合需求的外贸服务。企业应该多培育新增长点，如加快发展对‘一带一路’沿线国家及新兴国家贸易，同时提高生产经营效率。”张建平说，如果我们能够继续做好新旧动能转换，落实各方面工作，积极应对压力与市场不确定因素，下半年，我国外贸将有可能继续回稳，并朝长期向好的方向发展。',\n",
      " 'desc': '近日，世界贸易组织(WTO)对中国第六次贸易政策审议在日内瓦顺利结束。此次审议过程中，中国经贸体制、贸易投资领域取得的新进展等多方面得到积极',\n",
      " 'keywords': '外贸动能转换 中国又获好评',\n",
      " 'news_id': 461055299,\n",
      " 'source': '主流媒体-媒体平台',\n",
      " 'time': '07-26 11:15',\n",
      " 'title': '外贸动能转换 中国又获好评'}\n",
      "title:  外贸动能转换 中国又获好评\n",
      "content:  近日，世界贸易组织(WTO)对中国第六次贸易政策审议在日内瓦顺利结束。此次审议过程中，中国经贸体制、贸易投资领域取得的新进展等多方面得到积极评价，各成员对中国成为其重要经贸合作伙伴十分重视。对此，专家指出，虽然上半年中国进出口双下降，但中国在全球贸易经济中的地位仍不断上升，尤其是中国外贸新旧动能转换释放出的强劲动力，将推动对外贸易继续回稳、向好，也将为全球贸易增长作出重要贡献。新动能持续积累优势上半年，我国进出口同比下降3.3%，进口、出口分别下降4.7%和2.1%。虽然进出口双下降，但我国外贸新旧动能转换正加快进程，贸易结构不断优化。海关总署数据显示，1-6月，我国一般贸易进出口占进出口总值的56.4%，比去年同期提升1.2个百分点;民企出口增长3.6%，占出口总值的46.6%，占比继续保持首位。“一般贸易占比的持续上升体现出中国自主产品的比重在上升、自主创新能力在增强，我国对外贸易正向高附加值端发展，如高新技术产业等新业态在我国外贸发展中的势头已越来越强劲。而民企出口的快速发展带来了更多活力，外贸中的国内资本和投入品的增加，为我国外贸健康发展及结构优化提供了新动能。”国家发改委对外经济研究所国际合作室主任\n"
     ]
    }
   ],
   "source": [
    "# data explore\n",
    "from pprint import pprint\n",
    "import random\n",
    "print(len(data))\n",
    "idx = int(random.random()*len(data))\n",
    "print(\"id: \", idx)\n",
    "pprint(data[idx])\n",
    "print(\"title: \", data[idx]['title'])\n",
    "print(\"content: \", data[idx]['content'][:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2826eb9-7f27-4eb4-acbe-f5c1076656ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  2430752\n"
     ]
    }
   ],
   "source": [
    "# end exploring, from now on this is in acutal training script\n",
    "# create dataset\n",
    "# TODO test sharded\n",
    "import pandas as pd    \n",
    "import transformers\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "raw_data_train_path = \"/data/agent_h/news2016zh/news2016zh_train.json\"\n",
    "raw_data_valid_path = \"/data/agent_h/news2016zh/news2016zh_valid.json\"\n",
    "\n",
    "USE_SAMPLE_DATASET = False # use small set \n",
    "if USE_SAMPLE_DATASET:\n",
    "    train_data = pd.read_json(path_or_buf=raw_data_valid_path, lines=True)\n",
    "    train_data = train_data.to_dict('records')\n",
    "    train_data = train_data[:]\n",
    "else:\n",
    "    train_data = pd.read_json(path_or_buf=raw_data_train_path, lines=True)\n",
    "    train_data = train_data.to_dict('records')\n",
    "\n",
    "print(\"train size: \", len(train_data))\n",
    "\n",
    "train_data = Dataset.from_list(train_data)\n",
    "train_data = train_data.train_test_split(test_size=min(5000,int(len(train_data)*0.1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd70b00-3122-47ee-b86c-e29eae01f125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|                                                                     | 0/2425752 [00:00<?, ? examples/s]/home/agent_h/miniconda3/envs/vsr3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|█████████████████████████████████████████████████████| 2425752/2425752 [10:50<00:00, 3728.64 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████| 5000/5000 [00:01<00:00, 2614.27 examples/s]\n",
      "Saving the dataset (29/29 shards): 100%|█████████████████████| 2425752/2425752 [00:11<00:00, 212366.81 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|█████████████████████████████| 5000/5000 [00:00<00:00, 246078.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "def preprocess_cn_news_text_data(dataset,\n",
    "                                 tokenizer_base = \"/data/agent_h/llms/umt5-small\",\n",
    "                                 data_key = 'content',\n",
    "                                 label_key = 'title',\n",
    "                                 prefix=\"生成标题：\",\n",
    "                                 max_input_len=512,\n",
    "                                 max_target_len=64,\n",
    "                                ):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_base)\n",
    "    inputs = [prefix + text for text in dataset[data_key]]\n",
    "    inputs = tokenizer(inputs,\n",
    "                       max_length=max_input_len,\n",
    "                       truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(dataset[label_key],\n",
    "                           max_length=max_input_len, \n",
    "                           truncation=True)\n",
    "    \n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# TODO how to save this thing\n",
    "\n",
    "model_base = \"/data/agent_h/llms/umt5-small\"\n",
    "dataset_path = \"/data/agent_h/umt5-small-news2016zh-tokens-full\"\n",
    "# tokenize\n",
    "train_data = train_data.map(preprocess_cn_news_text_data,batched=True,batch_size=100000)\n",
    "train_data.save_to_disk(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cddfd2a-ec97-416a-8bce-a4e18115a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training in 11_t5_exp2.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
